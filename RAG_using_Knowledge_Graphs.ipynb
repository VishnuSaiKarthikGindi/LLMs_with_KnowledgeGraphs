{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-community langchain-groq neo4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Xfs37uCbzx",
        "outputId": "b9bd7bc1-4880-4d00-f723-de5927ea9345"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.7/293.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install requirements.txt"
      ],
      "metadata": {
        "id": "4EbxJNFUZOsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfis_vlPXiEX",
        "outputId": "fc3f3497-8dfe-4bf0-c8e3-8de38500fefd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.20.1)\n",
            "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "from string import Template\n",
        "from timeit import default_timer as timer\n",
        "from dotenv import load_dotenv\n",
        "from time import sleep\n",
        "\n",
        "#APIs\n",
        "#import openai\n",
        "from groq import Groq\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "#Langchain\n",
        "from langchain_core.documents import Document\n",
        "from langchain.graphs import Neo4jGraph\n",
        "from langchain.chains import GraphCypherQAChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "#from langchain.llms import AzureOpenAI\n",
        "\n",
        "#Streamlit\n",
        "import streamlit as st\n",
        "#from streamlit_chat import message"
      ],
      "metadata": {
        "id": "L2M3XkXEkEQT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "DS3iLtvtkINS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI API configuration\n",
        "#openai.api_type = \"azure\"\n",
        "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "#openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
        "#openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
        "#openai_deployment = \"chat-gpt35\""
      ],
      "metadata": {
        "id": "acJLpZQrkM5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neo4j configuration & constraints\n",
        "graph_db = GraphDatabase.driver(os.getenv(\"NEO4J_CONNECTION_URL\"), auth=(os.getenv(\"NEO4J_USER\"), os.getenv(\"NEO4J_PASSWORD\")))"
      ],
      "metadata": {
        "id": "zMJKWEQbkRPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Groq API using LangChain and Gemma\n",
        "llm_model = ChatGroq(groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "                     model_name = \"llama3-8b-8192\")"
      ],
      "metadata": {
        "id": "UYYm2mLRDrkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directories for different types of records\n",
        "directories = {\n",
        "    'patient_info': 'C:\\Users\\VISH NU\\RAG_using_Graphs_and_Langchain\\Data\\patient_info',\n",
        "    'patient_medical_history_briefs': 'C:\\Users\\VISH NU\\RAG_using_Graphs_and_Langchain\\Data\\patient_info'\n",
        "}"
      ],
      "metadata": {
        "id": "HPn7dYDUFAvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_document_from_text(file_path, document_type):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text_data = file.read().rstrip()\n",
        "    return Document(page_content=text_data, metadata={'type': document_type})\n",
        "\n",
        "def load_documents_from_directory(directory, document_type):\n",
        "    documents = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.txt'):  # Assuming the files are in .txt format\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            document = create_document_from_text(file_path, document_type)\n",
        "            documents.append(document)\n",
        "    return documents\n",
        "\n",
        "# Load documents from all directories\n",
        "all_documents = []\n",
        "for doc_type, dir_path in directories.items():\n",
        "    documents = load_documents_from_directory(dir_path, doc_type)\n",
        "    all_documents.extend(documents)"
      ],
      "metadata": {
        "id": "VKkTiMhsDoTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to call the Groq API\n",
        "def process_gpt(file_prompt, system_msg):\n",
        "    llm_model = Groq(groq_api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "    chat_completion = llm_model.chat.completions.create(\n",
        "        max_tokens=15000,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_msg,\n",
        "            }\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": file_prompt,\n",
        "            }\n",
        "        ],\n",
        "        model=\"llama3-8b-8192\")\n",
        "    results = chat_completion.choices[0].message.content\n",
        "    sleep(8)\n",
        "    return results\n",
        "\n",
        "# Function to take a list of Document objects and a prompt template, and return a json-object of all the entities and relationships\n",
        "def extract_entities_relationships(documents, prompt_template):\n",
        "    start = timer()\n",
        "    system_msg = \"You are a helpful IT-project and account management expert who extracts information from documents.\"\n",
        "    print(f\"Running pipeline for {len(documents)} documents\")\n",
        "    results = []\n",
        "    for i, document in enumerate(documents):\n",
        "        print(f\"Extracting entities and relationships for document {i+1}\")\n",
        "        try:\n",
        "            text = document.page_content\n",
        "            prompt = Template(prompt_template).substitute(ctext=text)\n",
        "            result = process_gpt(prompt, system_msg=system_msg)\n",
        "            results.append(json.loads(result))\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing document {i+1}: {e}\")\n",
        "    end = timer()\n",
        "    print(f\"Pipeline completed in {end-start} seconds\")\n",
        "    return results\n",
        "\n",
        "# Function to take a json-object of entities and relationships and generate cypher query for creating those entities\n",
        "def generate_cypher(json_obj):\n",
        "    e_statements = []\n",
        "    r_statements = []\n",
        "\n",
        "    e_label_map = {}\n",
        "\n",
        "    # loop through our json object\n",
        "    for i, obj in enumerate(json_obj):\n",
        "        print(f\"Generating cypher for document {i+1} of {len(json_obj)}\")\n",
        "        for entity in obj[\"entities\"]:\n",
        "            label = entity[\"label\"]\n",
        "            id = entity[\"id\"]\n",
        "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
        "            properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
        "\n",
        "            cypher = f'MERGE (n:{label} {{id: \"{id}\"}})'\n",
        "            if properties:\n",
        "                props_str = \", \".join(\n",
        "                    [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
        "                )\n",
        "                cypher += f\" ON CREATE SET {props_str}\"\n",
        "            e_statements.append(cypher)\n",
        "            e_label_map[id] = label\n",
        "\n",
        "        for rs in obj[\"relationships\"]:\n",
        "            src_id, rs_type, tgt_id = rs.split(\"|\")\n",
        "            src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
        "            tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
        "\n",
        "            src_label = e_label_map[src_id]\n",
        "            tgt_label = e_label_map[tgt_id]\n",
        "\n",
        "            cypher = f'MERGE (a:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
        "            r_statements.append(cypher)\n",
        "\n",
        "    with open(\"cyphers.txt\", \"w\") as outfile:\n",
        "        outfile.write(\"\\n\".join(e_statements + r_statements))\n",
        "\n",
        "    return e_statements + r_statements\n",
        "\n",
        "# Final function to bring all the steps together\n",
        "def ingestion_pipeline(all_documents, prompt_template):\n",
        "    # Extracting the entities and relationships from each document, append into one json_object\n",
        "    entities_relationships = extract_entities_relationships(all_documents, prompt_template)\n",
        "\n",
        "    # Generate and execute cypher statements\n",
        "    cypher_statements = generate_cypher(entities_relationships)\n",
        "    for i, stmt in enumerate(cypher_statements):\n",
        "        print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
        "        try:\n",
        "            graph_db.execute_query(stmt)\n",
        "        except Exception as e:\n",
        "            with open(\"failed_statements.txt\", \"w\") as f:\n",
        "                f.write(f\"{stmt} - Exception: {e}\\n\")"
      ],
      "metadata": {
        "id": "3ivEQkyAkUgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Using Langchain_experimental to create knowledge graphs by extracting entities and relationships within the document.\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "\n",
        "llm_transformer=LLMGraphTransformer(llm=llm)\n",
        "graph_documents=llm_transformer.convert_to_graph_documents(documents)"
      ],
      "metadata": {
        "id": "Gb01jutvOOoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_info_prompt_template = \"\"\"\n",
        "From the Patient Info below, extract the following Entities & relationships described in the mentioned format\n",
        "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
        "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
        "    Entity Types:\n",
        "    label:'Patient',id:string,name:string,age:int,gender:string //Patient information; `id` property is the unique identifier for the patient; 'name' is the patient's name; 'age' is the patient's age; 'gender' is the patient's gender\n",
        "    label:'Contact',id:string,relation:string,name:string,phone:string,email:string //Contact information; `id` property is the unique identifier for the contact; 'relation' is the relationship to the patient; 'name' is the contact's name; 'phone' is the contact's phone number; 'email' is the contact's email address\n",
        "\n",
        "2. Next generate each relationship as triples of head, relationship, and tail. To refer to the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
        "    Relationship types:\n",
        "    patient|HAS_CONTACT|contact\n",
        "\n",
        "3. The output should look like :\n",
        "{\n",
        "    \"entities\": [{\"label\":\"Patient\",\"id\":string,\"name\":string,\"age\":int,\"gender\":string}],\n",
        "    \"relationships\": [\"patientid|HAS_CONTACT|contactid\"]\n",
        "}\n",
        "\n",
        "Case Sheet:\n",
        "$ctext\n",
        "\"\"\"\n",
        "\n",
        "patient_medical_history_prompt_template = \"\"\"\n",
        "From the Medical History below, extract the following Entities & relationships described in the mentioned format\n",
        "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
        "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
        "    Entity Types:\n",
        "    label:'Patient',id:string,name:string //Patient information; `id` property is the unique identifier for the patient; 'name' is the patient's name\n",
        "    label:'Condition',id:string,name:string,description:string //Medical Condition; `id` property is the unique identifier for the condition; 'name' is the name of the condition; 'description' is a brief description of the condition\n",
        "    label:'Allergy',id:string,name:string //Allergy details; `id` property is the unique identifier for the allergy; 'name' is the name of the substance the patient is allergic to\n",
        "    label:'Medication',id:string,name:string,dosage:string,frequency:string //Medication details; `id` property is the unique identifier for the medication; 'name' is the name of the medication; 'dosage' is the dosage of the medication; 'frequency' is the frequency of administration\n",
        "    label:'LabTest',id:string,name:string,result:string,date:string //Lab Test details; `id` property is the unique identifier for the lab test; 'name' is the name of the lab test; 'result' is the result of the lab test; 'date' is the date the test was conducted\n",
        "    label:'Visit',id:string,date:string,reason:string,doctor:string //Visit details; `id` property is the unique identifier for the visit; 'date' is the date of the visit; 'reason' is the reason for the visit; 'doctor' is the name of the doctor who attended the visit\n",
        "\n",
        "2. Next generate each relationship as triples of head, relationship, and tail. To refer to the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
        "    Relationship types:\n",
        "    patient|HAS_CONDITION|condition\n",
        "    patient|HAS_ALLERGY|allergy\n",
        "    patient|TAKES_MEDICATION|medication\n",
        "    patient|UNDERGOES|labtest\n",
        "    patient|HAS_VISIT|visit\n",
        "\n",
        "3. The output should look like :\n",
        "{\n",
        "    \"entities\": [{\"label\":\"Patient\",\"id\":string,\"name\":string}],\n",
        "    \"relationships\": [\"patientid|HAS_CONDITION|conditionid\"],\n",
        "    \"relationships\": [\"patientid|HAS_ALLERGY|allergyid\"],\n",
        "    \"relationships\": [\"patientid|TAKES_MEDICATION|medicationid\"],\n",
        "    \"relationships\": [\"patientid|UNDERGOES|labtestid\"],\n",
        "    \"relationships\": [\"patientid|HAS_VISIT|visitid\"]\n",
        "}\n",
        "\n",
        "Case Sheet:\n",
        "$ctext\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "HsB-iJUtkou1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = {\n",
        "    'patient_info': patient_info_prompt_template,\n",
        "    'patient_medical_history_briefs': patient_medical_history_prompt_template,\n",
        "}\n",
        "\n",
        "ingestion_pipeline(folders)"
      ],
      "metadata": {
        "id": "C3Dxbqwjktzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher_generation_template = \"\"\"\n",
        "You are an expert Neo4j Cypher translator who converts English to Cypher based on the Neo4j Schema provided, following the instructions below:\n",
        "1. Generate Cypher query compatible ONLY for Neo4j Version 5\n",
        "2. Do not use EXISTS, SIZE, HAVING keywords in the cypher. Use alias when using the WITH keyword\n",
        "3. Use only Nodes and relationships mentioned in the schema\n",
        "4. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Patient, use `toLower(patient.name) contains 'john'`. To search for a Medical Condition, use 'toLower(condition.name) contains 'diabetes'`. To search for a Medication, use `toLower(medication.name) contains 'aspirin'`.)\n",
        "5. Never use relationships that are not mentioned in the given schema\n",
        "6. When asked about patients, match the properties using case-insensitive matching and the OR-operator, E.g., to find a patient named John Doe, use `toLower(patient.name) contains 'john' OR toLower(patient.name) contains 'doe'`.\n",
        "\n",
        "schema: {\n",
        "  Patient: {properties: ['id', 'name', 'age', 'gender']},\n",
        "  Contact: {properties: ['id', 'relation', 'name', 'phone', 'email']},\n",
        "  Condition: {properties: ['id', 'name', 'description']},\n",
        "  Medication: {properties: ['id', 'name', 'dosage', 'frequency']},\n",
        "  LabTest: {properties: ['id', 'name', 'result', 'date']},\n",
        "  Visit: {properties: ['id', 'date', 'reason', 'doctor']},\n",
        "  Relationships: [\n",
        "    {Patient: 'HAS_CONTACT', Contact},\n",
        "    {Patient: 'HAS_CONDITION', Condition},\n",
        "    {Patient: 'TAKES_MEDICATION', Medication},\n",
        "    {Patient: 'UNDERGOES', LabTest},\n",
        "    {Patient: 'HAS_VISIT', Visit}\n",
        "  ]\n",
        "}\n",
        "\n",
        "Examples:\n",
        "Question: Which patients have undergone lab tests for diabetes?\n",
        "Answer: ```MATCH (p:Patient)-[:UNDERGOES]->(lt:LabTest)\n",
        "WHERE toLower(lt.name) contains 'diabetes' OR toLower(lt.result) contains 'diabetes'\n",
        "RETURN p.name AS PatientName, lt.name AS LabTestName, lt.result AS Result```\n",
        "\n",
        "Question: Which patients are taking aspirin?\n",
        "Answer: ```MATCH (p:Patient)-[:TAKES_MEDICATION]->(m:Medication)\n",
        "WHERE toLower(m.name) contains 'aspirin'\n",
        "RETURN p.name AS PatientName, m.name AS MedicationName, m.dosage AS Dosage, m.frequency AS Frequency```\n",
        "\n",
        "Question: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "u3JcFNCEKpIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cypher generation prompt\n",
        "cypher_generation_template = \"\"\"\n",
        "You are an expert Neo4j Cypher translator who converts English to Cypher based on the Neo4j Schema provided, following the instructions below:\n",
        "1. Generate Cypher query compatible ONLY for Neo4j Version 5\n",
        "2. Do not use EXISTS, SIZE, HAVING keywords in the cypher. Use alias when using the WITH keyword\n",
        "3. Use only Nodes and relationships mentioned in the schema\n",
        "4. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Patient, use `toLower(patient.name) contains 'john'`. To search for a Medical Condition, use 'toLower(condition.name) contains 'diabetes'`. To search for a Medication, use `toLower(medication.name) contains 'aspirin'`.)\n",
        "5. Never use relationships that are not mentioned in the given schema\n",
        "6. When asked about patients, match the properties using case-insensitive matching and the OR-operator, E.g., to find a patient named John Doe, use `toLower(patient.name) contains 'john' OR toLower(patient.name) contains 'doe'`.\n",
        "\n",
        "schema: {schema}\n",
        "\n",
        "Examples:\n",
        "Question: Which patients have undergone lab tests for diabetes?\n",
        "Answer: ```MATCH (p:Patient)-[:UNDERGOES]->(lt:LabTest)\n",
        "WHERE toLower(lt.name) contains 'diabetes' OR toLower(lt.result) contains 'diabetes'\n",
        "RETURN p.name AS PatientName, lt.name AS LabTestName, lt.result AS Result```\n",
        "\n",
        "Question: Which patients are taking aspirin?\n",
        "Answer: ```MATCH (p:Patient)-[:TAKES_MEDICATION]->(m:Medication)\n",
        "WHERE toLower(m.name) contains 'aspirin'\n",
        "RETURN p.name AS PatientName, m.name AS MedicationName, m.dosage AS Dosage, m.frequency AS Frequency```\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "cypher_prompt = PromptTemplate(\n",
        "    template = cypher_generation_template,\n",
        "    input_variables = [\"schema\", \"question\"]\n",
        ")\n",
        "\n",
        "CYPHER_QA_TEMPLATE = \"\"\"You are an assistant that helps to form nice and human understandable answers.\n",
        "The information part contains the provided information that you must use to construct an answer.\n",
        "The provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
        "Make the answer sound as a response to the question. Do not mention that you based the result on the given information.\n",
        "If the provided information is empty, say that you don't know the answer.\n",
        "Final answer should be easily readable and structured.\n",
        "Information:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "\n",
        "qa_prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"], template=CYPHER_QA_TEMPLATE\n",
        ")\n",
        "\n",
        "def query_graph(user_input):\n",
        "    graph = Neo4jGraph(url=os.getenv(\"NEO4J_CONNECTION_URL\"), username=os.getenv(\"NEO4J_USER\"), password=os.getenv(\"NEO4J_PASSWORD\"))\n",
        "    chain = GraphCypherQAChain.from_llm(\n",
        "        llm=llm_model,\n",
        "        graph=graph,\n",
        "        verbose=True,\n",
        "        return_intermediate_steps=True,\n",
        "        cypher_prompt=cypher_prompt,\n",
        "        qa_prompt=qa_prompt\n",
        "        )\n",
        "    result = chain(user_input)\n",
        "    return result"
      ],
      "metadata": {
        "id": "AGODVV3mlbwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st.set_page_config(layout=\"wide\")\n",
        "\n",
        "if \"user_msgs\" not in st.session_state:\n",
        "    st.session_state.user_msgs = []\n",
        "if \"system_msgs\" not in st.session_state:\n",
        "    st.session_state.system_msgs = []\n",
        "\n",
        "title_col, empty_col, img_col = st.columns([2, 1, 2])\n",
        "\n",
        "with title_col:\n",
        "    st.title(\"Conversational Agent for Healthcare Clinics\")\n",
        "with img_col:\n",
        "    st.image(\"https://dist.neo4j.com/wp-content/uploads/20210423062553/neo4j-social-share-21.png\", width=200)\n",
        "\n",
        "user_input = st.text_input(\"Enter your question\", key=\"input\")\n",
        "if user_input:\n",
        "    with st.spinner(\"Processing your question...\"):\n",
        "        st.session_state.user_msgs.append(user_input)\n",
        "        start = timer()\n",
        "\n",
        "        try:\n",
        "            result = query_graph(user_input)\n",
        "\n",
        "            intermediate_steps = result[\"intermediate_steps\"]\n",
        "            cypher_query = intermediate_steps[0][\"query\"]\n",
        "            database_results = intermediate_steps[1][\"context\"]\n",
        "\n",
        "            answer = result[\"result\"]\n",
        "            st.session_state.system_msgs.append(answer)\n",
        "        except Exception as e:\n",
        "            st.write(\"Failed to process question. Please try again.\")\n",
        "            print(e)\n",
        "\n",
        "    st.write(f\"Time taken: {timer() - start:.2f}s\")\n",
        "\n",
        "    col1, col2, col3 = st.columns([1, 1, 1])\n",
        "\n",
        "    # Display the chat history\n",
        "    with col1:\n",
        "        if st.session_state[\"system_msgs\"]:\n",
        "            for i in range(len(st.session_state[\"system_msgs\"]) - 1, -1, -1):\n",
        "                message(st.session_state[\"system_msgs\"][i], key = str(i) + \"_assistant\")\n",
        "                message(st.session_state[\"user_msgs\"][i], is_user=True, key=str(i) + \"_user\")\n",
        "\n",
        "    with col2:\n",
        "        if cypher_query:\n",
        "            st.text_area(\"Last Cypher Query\", cypher_query, key=\"_cypher\", height=240)\n",
        "\n",
        "    with col3:\n",
        "        if database_results:\n",
        "            st.text_area(\"Last Database Results\", database_results, key=\"_database\", height=240)\n"
      ],
      "metadata": {
        "id": "jzJ-HJPzlfwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}